{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOpMBpGfuC1O"
      },
      "source": [
        "## **Step 1: Load Data and Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hcM4cheFqsYQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Loading the dateset\n",
        "url = \"https://raw.githubusercontent.com/mohd-faizy/CAREER-TRACK-Data-Scientist-with-Python/main/__Projects__/14_Modeling%20Car%20Insurance%20Claim%20Outcomes/car_insurance.csv\"\n",
        "df_ml = pd.read_csv(url)\n",
        "\n",
        "# Define the mappings for categorical columns\n",
        "mappings = {\n",
        "    'driving_experience': {'0-9y': 0, '10-19y': 1, '20-29y': 2, '30y+': 3},\n",
        "    'education': {'none': 0, 'high school': 1, 'university': 2},\n",
        "    'income': {'poverty': 0, 'middle class': 1, 'working class': 2, 'upper class': 3},\n",
        "    'vehicle_year': {'before 2015': 0, 'after 2015': 1},\n",
        "    'vehicle_type': {'sedan': 0, 'sports car': 1},\n",
        "    'postal_code': {10238: 1, 32765: 2, 92101: 3, 21217: 4}\n",
        "}\n",
        "\n",
        "# Replace values based on mappings\n",
        "df_ml.replace(mappings, inplace=True)\n",
        "\n",
        "# Convert categorical columns to categorical data type\n",
        "cat_cols = ['age', 'gender', 'driving_experience', 'education', 'income', 'vehicle_ownership',\n",
        "            'vehicle_year', 'married', 'children', 'vehicle_type', 'postal_code']\n",
        "df_ml[cat_cols] = df_ml[cat_cols].astype('category')\n",
        "\n",
        "# Handling missing values in 'credit_score' and 'annual_mileage'\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df_ml['credit_score'] = imputer.fit_transform(df_ml[['credit_score']])\n",
        "df_ml['annual_mileage'] = imputer.fit_transform(df_ml[['annual_mileage']])\n",
        "\n",
        "# Scaling numerical columns\n",
        "scaler = MinMaxScaler()\n",
        "df_ml[['credit_score', 'annual_mileage']] = scaler.fit_transform(df_ml[['credit_score', 'annual_mileage']])\n",
        "\n",
        "# Drop columns not needed for the model\n",
        "columns_to_drop = ['id']\n",
        "df_ml = df_ml.drop(columns_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcPSrvYRutqf"
      },
      "source": [
        "## **Step 2: Column Transformations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pLMvzGzerIv1"
      },
      "outputs": [],
      "source": [
        "# Define columns for preprocessing\n",
        "numerical_features = ['credit_score', 'annual_mileage', 'speeding_violations', 'duis', 'past_accidents']\n",
        "categorical_features = ['age', 'gender', 'driving_experience', 'education', 'income', 'vehicle_ownership',\n",
        "                        'vehicle_year', 'married', 'children', 'vehicle_type', 'postal_code']\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine numerical and categorical transformers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply the transformations\n",
        "X_preprocessed = preprocessor.fit_transform(df_ml)\n",
        "\n",
        "# Capture transformed column names for categorical features\n",
        "categorical_columns = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
        "\n",
        "# Combine numerical and transformed categorical column names\n",
        "all_column_names = numerical_features + list(categorical_columns)\n",
        "\n",
        "# Convert NumPy array back to a DataFrame with correct column names\n",
        "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT0xsYHbuxxB"
      },
      "source": [
        "## **Step 3: Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dKMsetI8rLap"
      },
      "outputs": [],
      "source": [
        "# Split the DataFrame into features (X) and target (y)\n",
        "X = X_preprocessed_df\n",
        "y = df_ml['outcome']\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab3P93TXu33G"
      },
      "source": [
        "## **Step 4: Define and Train Individual Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5coTfw-urNHd",
        "outputId": "19e6f229-2983-4527-f239-667a689a4fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8485\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.92      0.89      1367\n",
            "         1.0       0.79      0.70      0.75       633\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.81      0.82      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "Random Forest Accuracy: 0.8285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.91      0.88      1367\n",
            "         1.0       0.77      0.66      0.71       633\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.81      0.78      0.79      2000\n",
            "weighted avg       0.82      0.83      0.82      2000\n",
            "\n",
            "Gradient Boosting Accuracy: 0.8465\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.91      0.89      1367\n",
            "         1.0       0.79      0.70      0.74       633\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.81      0.82      2000\n",
            "weighted avg       0.84      0.85      0.84      2000\n",
            "\n",
            "SVM Accuracy: 0.8455\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.90      0.89      1367\n",
            "         1.0       0.78      0.72      0.75       633\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.81      0.82      2000\n",
            "weighted avg       0.84      0.85      0.84      2000\n",
            "\n",
            "KNN Accuracy: 0.8135\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.89      0.87      1367\n",
            "         1.0       0.73      0.65      0.69       633\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.79      0.77      0.78      2000\n",
            "weighted avg       0.81      0.81      0.81      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the individual models\n",
        "lr = LogisticRegression(random_state=42)\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "svm = SVC(probability=True, random_state=42)  # Set probability=True for soft voting\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Train each model\n",
        "lr.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "gb.fit(X_train, y_train)\n",
        "svm.fit(X_train, y_train)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with each model\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Evaluate each model\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(classification_report(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVn33sBpu8k4"
      },
      "source": [
        "## **Step 5: Ensemble Voting Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3QGNtItrSPf",
        "outputId": "f5826acd-a749-44d2-8213-a548e9c76710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting Classifier Accuracy: 0.848\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.91      0.89      1367\n",
            "         1.0       0.79      0.71      0.75       633\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.81      0.82      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Define the voting classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('lr', lr),\n",
        "    ('rf', rf),\n",
        "    ('gb', gb),\n",
        "    ('svm', svm),\n",
        "    ('knn', knn)\n",
        "], voting='hard')  # Use 'soft' for probability-based voting\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the voting classifier\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the voting classifier\n",
        "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred_voting))\n",
        "print(classification_report(y_test, y_pred_voting))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6hPlhh2vnA1"
      },
      "source": [
        "## **Step 5: Hyperparameter Tunning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwCw1YwtsYhi"
      },
      "source": [
        "Once the best-performing model identified, we can further improve its performance by tuning its hyperparameters using `GridSearchCV` from sklearn.model_selection. Grid search is a powerful method for systematically testing a range of hyperparameters to find the optimal set that maximizes the model's performance.\n",
        "\n",
        "**Step-by-Step Guide for Hyperparameter Tuning with GridSearchCV**\n",
        "\n",
        "- `Identify the Best Model`: Suppose the best model from your previous evaluations is GradientBoostingClassifier.\n",
        "\n",
        "- `Define Hyperparameter Grid`: Create a dictionary specifying the hyperparameters and the range of values you want to test.\n",
        "\n",
        "- `Set Up Grid Search`: Use GridSearchCV to perform an exhaustive search over the specified parameter values.\n",
        "\n",
        "- `Fit and Evaluate`: Fit the model with the training data and evaluate the best parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI_uej_ovkZ_"
      },
      "source": [
        "### **Define Hyperparameter Grid**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_9tphq6xsZhY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MKZdFKIvw1t"
      },
      "source": [
        "### **Set Up Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "43JVvoLpscXv"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=gb, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdU2D54Nv02f"
      },
      "source": [
        "### **Fit and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EO_lPGlseUv",
        "outputId": "e37ca97d-6764-4b29-85b9-c2f91d581363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters found:  {'learning_rate': 0.1, 'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
            "Best Model Accuracy: 0.8475\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.91      0.89      1367\n",
            "         1.0       0.78      0.72      0.75       633\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.81      0.82      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fit the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best hyperparameters found: \", best_params)\n",
        "\n",
        "# Get the best estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "# Print accuracy and classification report\n",
        "print(\"Best Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
        "print(classification_report(y_test, y_pred_best))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4nZ2_kAKc8K"
      },
      "source": [
        "```\n",
        "Best hyperparameters found:  {'learning_rate': 0.1, 'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
        "Best Model Accuracy: 0.8475\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       0.87      0.91      0.89      1367\n",
        "         1.0       0.78      0.72      0.75       633\n",
        "\n",
        "    accuracy                           0.85      2000\n",
        "   macro avg       0.83      0.81      0.82      2000\n",
        "weighted avg       0.85      0.85      0.85      2000\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgtty-Idv4cO"
      },
      "source": [
        "### **Example with Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtbplM7vshWD",
        "outputId": "f79d6a14-a757-4064-ed26-edea89a57abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters found for Logistic Regression:  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Logistic Regression Model Accuracy: 0.848\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.91      0.89      1367\n",
            "         1.0       0.79      0.70      0.75       633\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.81      0.82      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid_lr = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_lr = GridSearchCV(estimator=lr, param_grid=param_grid_lr, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params_lr = grid_search_lr.best_params_\n",
        "print(\"Best hyperparameters found for Logistic Regression: \", best_params_lr)\n",
        "\n",
        "# Get the best estimator\n",
        "best_model_lr = grid_search_lr.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred_best_lr = best_model_lr.predict(X_test)\n",
        "\n",
        "# Print accuracy and classification report\n",
        "print(\"Best Logistic Regression Model Accuracy:\", accuracy_score(y_test, y_pred_best_lr))\n",
        "print(classification_report(y_test, y_pred_best_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iHxeOjVKjMx"
      },
      "source": [
        "```\n",
        "Best hyperparameters found for Logistic Regression:  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
        "Best Logistic Regression Model Accuracy: 0.848\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       0.87      0.91      0.89      1367\n",
        "         1.0       0.79      0.70      0.75       633\n",
        "\n",
        "    accuracy                           0.85      2000\n",
        "   macro avg       0.83      0.81      0.82      2000\n",
        "weighted avg       0.85      0.85      0.85      2000\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
